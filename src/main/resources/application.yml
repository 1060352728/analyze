server:
  port: 8088
spring:
  jpa:
    show-sql: true
  datasource:
    druid:
      type: com.alibaba.druid.pool.DruidDataSource
      driver-class-name: com.mysql.jdbc.Driver
      url: jdbc:mysql://localhost:3306/executor_service?useUnicode=true&characterEncoding=utf-8
      username: root
      password: root
      initial-size: 10      # 初始化连接大小
      min-idle: 5       # 最小空闲连接数
      max-active: 30
      max-wait: 30000
      time-between-eviction-runs-millis: 60000    # 可关闭的空闲连接间隔时间
      min-evictable-idle-time-millis: 300000     # 配置连接在池中的最小生存时间
      validation-query: select '1' from dual
      test-while-idle: true
      test-on-borrow: false
      test-on-return: false
      # 打开PSCache，并且指定每个连接上PSCache的大小
      pool-prepared-statements: true
      max-open-prepared-statements: 20
      max-pool-prepared-statement-per-connection-size: 20
      # 配置监控统计拦截的filters
      filters: stat
      stat-view-servlet:
        url-pattern: /druid/*
        reset-enable: false
        login-username: admin
        login-password: 123456
    hikari:
      connection-timeout: 1000000
  kafka:
    # 指定kafka 代理地址，可以多个
    bootstrap-servers: 127.0.0.1:9092
    producer:
      retries: 0
      # 每次批量发送消息的数量
      batch-size: 16384
      # 缓存容量
      buffer-memory: 33554432
      # 指定消息key和消息体的编解码方式
      key-serializer: org.apache.kafka.common.serialization.StringSerializer
      value-serializer: org.apache.kafka.common.serialization.StringSerializer
    consumer:
      # 指定默认消费者group id
      group-id: metric-group
      auto-commit-interval: 100
      auto-offset-reset: earliest
      enable-auto-commit: true
      # 指定消息key和消息体的编解码方式
      key-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      value-deserializer: org.apache.kafka.common.serialization.StringDeserializer
    # 指定listener 容器中的线程数，用于提高并发量
    listener:
      concurrency: 3